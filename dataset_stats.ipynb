{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f680e2-6c14-47bc-ab15-acfa2962cb50",
   "metadata": {},
   "source": [
    "# Dataset stats workbook\n",
    "- Created by Gabe (2022-05-07)\n",
    "- For Theo to use to compute dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac6586fa-b1ae-43dc-9f07-d918416fbe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from run_experiment import init_experiment_state_and_iterator\n",
    "from dreamcoder.program import Program\n",
    "from src.config_builder import build_config\n",
    "from src.experiment_iterator import EXPORT_DIRECTORY\n",
    "from src.task_loaders import GroundTruthOrderedTaskBatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "716bfc6c-f74d-4a0f-b632-6426265d889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOMAIN = \"drawings_nuts_bolts\"\n",
    "#DOMAIN = \"drawings_furniture\"\n",
    "#DOMAIN = \"drawings_dials\"\n",
    "#DOMAIN = \"drawings_wheels\"\n",
    "\n",
    "DOMAIN = \"clevr\"\n",
    "#DOMAIN = \"re2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b4cfe58c-677d-49bc-8f8f-8e3144cac3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = build_config(\n",
    "    experiment_name=\"test_experiment\",\n",
    "    experiment_type=\"stitch\",\n",
    "    domain=DOMAIN,\n",
    "    task_batcher=\"ground_truth_ordered_task_batcher\",\n",
    "    random_seed=111,\n",
    "    global_batch_size=\"all\",\n",
    "    codex_params={},\n",
    "    stitch_params={},\n",
    "    compute_likelihoods=False,\n",
    "    compute_description_lengths=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b53f292e-f7ed-48c3-adc3-2aa03653d3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 CLEVR question classes: dict_keys(['2_localization', '2_transform', '1_zero_hop', '1_single_or', '1_same_relate_restricted', '1_compare_integer', '1_one_hop', '2_remove'])\n",
      "Loading dataset 1_compare_integer: train: found 6 tasks.\n",
      "Loading dataset 1_compare_integer: val: found 4 tasks.\n",
      "Loading dataset 1_one_hop: train: found 30 tasks.\n",
      "Loading dataset 1_one_hop: val: found 10 tasks.\n",
      "Loading dataset 1_single_or: train: found 25 tasks.\n",
      "Loading dataset 1_single_or: val: found 10 tasks.\n",
      "Loading dataset 1_zero_hop: train: found 30 tasks.\n",
      "Loading dataset 1_zero_hop: val: found 30 tasks.\n",
      "Loading dataset 2_localization: train: found 58 tasks.\n",
      "Loading dataset 2_localization: val: found 30 tasks.\n",
      "Loading dataset 2_remove: train: found 23 tasks.\n",
      "Loading dataset 2_remove: val: found 9 tasks.\n",
      "Loading dataset 2_transform: train: found 22 tasks.\n",
      "Loading dataset 2_transform: val: found 10 tasks.\n",
      "Loaded a total of 194 training tasks and 103 testing tasks for curriculum datasets: [] and main datasest: ['2_localization', '2_remove', '2_transform', '1_zero_hop', '1_single_or', '1_one_hop', '1_compare_integer']\n",
      "Loaded 8 CLEVR question classes: dict_keys(['2_localization', '2_transform', '1_zero_hop', '1_single_or', '1_same_relate_restricted', '1_compare_integer', '1_one_hop', '2_remove'])\n",
      "Excluding task: 18-2_transform-If all of the small blue cubes became small, how many small things would there be?\n",
      "Excluding task: 19-2_transform-If all of the small spheres became small, how many small things would there be?\n",
      "Excluding task: 21-2_transform-If all of the large brown rubber things became large, how many large things would there be?\n",
      "Loaded 8 CLEVR question classes: dict_keys(['2_localization', '2_transform', '1_zero_hop', '1_single_or', '1_same_relate_restricted', '1_compare_integer', '1_one_hop', '2_remove'])\n",
      "Loading dataset 1_compare_integer: train: found 6 tasks.\n",
      "Loading dataset 1_compare_integer: val: found 4 tasks.\n",
      "Loading dataset 1_one_hop: train: found 30 tasks.\n",
      "Loading dataset 1_one_hop: val: found 10 tasks.\n",
      "Loading dataset 1_single_or: train: found 25 tasks.\n",
      "Loading dataset 1_single_or: val: found 10 tasks.\n",
      "Loading dataset 1_zero_hop: train: found 30 tasks.\n",
      "Loading dataset 1_zero_hop: val: found 30 tasks.\n",
      "Loading dataset 2_localization: train: found 58 tasks.\n",
      "Loading dataset 2_localization: val: found 30 tasks.\n",
      "Loading dataset 2_remove: train: found 23 tasks.\n",
      "Loading dataset 2_remove: val: found 9 tasks.\n",
      "Loading dataset 2_transform: train: found 22 tasks.\n",
      "Loading dataset 2_transform: val: found 10 tasks.\n",
      "Loaded a total of 194 training tasks and 103 testing tasks for curriculum datasets: [] and main datasest: ['2_localization', '2_remove', '2_transform', '1_zero_hop', '1_single_or', '1_one_hop', '1_compare_integer']\n",
      "Loaded 8 CLEVR question classes: dict_keys(['2_localization', '2_transform', '1_zero_hop', '1_single_or', '1_same_relate_restricted', '1_compare_integer', '1_one_hop', '2_remove'])\n",
      "Found language for 2/2 tasks\n",
      "Found vocabularies of n=[59] for train and n=[62] for test.\n",
      "============LOGGING TASK_BATCHER============\n",
      "Task batcher: ground_truth_ordered_task_batcher\n",
      "Initializing batcher over tasks: \n",
      "train tasks: 191\n",
      "test tasks: 103\n",
      "global_batch_size: all\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "experiment_state, experiment_iterator = init_experiment_state_and_iterator(\n",
    "    {}, config\n",
    ")\n",
    "experiment_state.initialize_ground_truth_task_frontiers(task_split=\"train\")\n",
    "experiment_state.initialize_ground_truth_task_frontiers(task_split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6c9bfc11-5d32-4ac6-a169-42b92de4cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n"
     ]
    }
   ],
   "source": [
    "train_frontiers = experiment_state.get_frontiers_for_ids(task_split=\"train\", task_ids=\"all\")\n",
    "print(len(train_frontiers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0f8ee535-e696-4931-8ed9-2afd81b65c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Frontier(entries=[FrontierEntry(program=(lambda (clevr_lt? (clevr_count (clevr_fold (clevr_fold (clevr_fold $0 clevr_empty (lambda (lambda (clevr_if (clevr_eq_size clevr_large (clevr_query_size $1)) (clevr_add $1 $0) $0)))) clevr_empty (lambda (lambda (clevr_if (clevr_eq_material clevr_rubber (clevr_query_material $1)) (clevr_add $1 $0) $0)))) clevr_empty (lambda (lambda (clevr_if (clevr_eq_shape clevr_cube (clevr_query_shape $1)) (clevr_add $1 $0) $0))))) (clevr_count (clevr_fold (clevr_fold (clevr_fold $0 clevr_empty (lambda (lambda (clevr_if (clevr_eq_size clevr_large (clevr_query_size $1)) (clevr_add $1 $0) $0)))) clevr_empty (lambda (lambda (clevr_if (clevr_eq_color clevr_green (clevr_query_color $1)) (clevr_add $1 $0) $0)))) clevr_empty (lambda (lambda (clevr_if (clevr_eq_material clevr_rubber (clevr_query_material $1)) (clevr_add $1 $0) $0))))))), logPrior=0.0, logLikelihood=0.0], task=0-1_compare_integer-Is the number of large rubber cubes less than the number of large green rubber things? ((lambda (clevr_lt? (clevr_count (clevr_fold (clevr_fold (clevr_fold $0 clevr_empty (lambda (lambda (clevr_if (clevr_eq_size clevr_large (clevr_query_size $1)) (clevr_add $1 $0) $0)))) clevr_empty (lambda (lambda (clevr_if (clevr_eq_material clevr_rubber (clevr_query_material $1)) (clevr_add $1 $0) $0)))) clevr_empty (lambda (lambda (clevr_if (clevr_eq_shape clevr_cube (clevr_query_shape $1)) (clevr_add $1 $0) $0))))) (clevr_count (clevr_fold (clevr_fold (clevr_fold $0 clevr_empty (lambda (lambda (clevr_if (clevr_eq_size clevr_large (clevr_query_size $1)) (clevr_add $1 $0) $0)))) clevr_empty (lambda (lambda (clevr_if (clevr_eq_color clevr_green (clevr_query_color $1)) (clevr_add $1 $0) $0)))) clevr_empty (lambda (lambda (clevr_if (clevr_eq_material clevr_rubber (clevr_query_material $1)) (clevr_add $1 $0) $0)))))))))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A frontier contains one or more programs that solve a task\n",
    "train_frontiers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d55172ba-429d-4dc5-a263-414e6641b07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda (clevr_lt? (clevr_count (clevr_fold (clevr_fold (clevr_fold $0 clevr_empty (lambda (lambda (clevr_if (clevr_eq_size clevr_large (clevr_query_size $1)) (clevr_add $1 $0) $0)))) clevr_empty (lambda (lambda (clevr_if (clevr_eq_material clevr_rubber (clevr_query_material $1)) (clevr_add $1 $0) $0)))) clevr_empty (lambda (lambda (clevr_if (clevr_eq_shape clevr_cube (clevr_query_shape $1)) (clevr_add $1 $0) $0))))) (clevr_count (clevr_fold (clevr_fold (clevr_fold $0 clevr_empty (lambda (lambda (clevr_if (clevr_eq_size clevr_large (clevr_query_size $1)) (clevr_add $1 $0) $0)))) clevr_empty (lambda (lambda (clevr_if (clevr_eq_color clevr_green (clevr_query_color $1)) (clevr_add $1 $0) $0)))) clevr_empty (lambda (lambda (clevr_if (clevr_eq_material clevr_rubber (clevr_query_material $1)) (clevr_add $1 $0) $0)))))))\n"
     ]
    }
   ],
   "source": [
    "# The first program in the frontier. You can assume all domains have one program per frontier.\n",
    "p = train_frontiers[0].entries[0].program\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9a293639-b791-4ccd-bb7e-7e2f9216487f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# description length\n",
    "len(Program.left_order_tokens(p, show_vars=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9aed51c9-d2a0-48c1-a08b-4354756a94fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "825"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# character length\n",
    "len(str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aa0fb726-c5b9-4d18-8ce4-62d9664ac325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(theoxo): Compute and report the following for the paper\n",
    "# - number of programs in each domain, broken down by train/test\n",
    "# - mean and std of description and character lengths for all domains, broken down by train/test\n",
    "# - any other relevant program stats you can think of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "116e6d38-01e2-4f89-a6ae-842bb2a0af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for t in [\"train\", \"test\"]:\n",
    "    data[t] = {}\n",
    "    frontiers = experiment_state.get_frontiers_for_ids(task_split=t, task_ids=\"all\")\n",
    "    data[t][\"count\"] = len(frontiers)\n",
    "    data[t][\"dls\"] = np.array([len(Program.left_order_tokens(frontier.entries[0].program, show_vars=True)) for frontier in frontiers])\n",
    "    data[t][\"chars\"] = np.array([len(str(frontier.entries[0].program)) for frontier in frontiers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d1874c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain=re2\n",
      "Number of programs: train=491 test=500\n",
      "Mean and std-dev of description length: train=(41.032586558044805, 27.01585408468125) test=(38.95, 26.11121406599088)\n",
      "Mean and std-dev of char length: train=(276.4725050916497, 179.9200681249624) test=(262.742, 172.69280076482633)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Domain={DOMAIN}\")\n",
    "print(f\"Number of programs: train={data['train']['count']} test={data['test']['count']}\")\n",
    "print(f\"Mean and std-dev of description length: train={(np.mean(data['train']['dls']), np.std(data['train']['dls']))} test={(np.mean(data['test']['dls']), np.std(data['test']['dls']))}\")\n",
    "print(f\"Mean and std-dev of char length: train={(np.mean(data['train']['chars']), np.std(data['train']['chars']))} test={(np.mean(data['test']['chars']), np.std(data['test']['chars']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13e797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
