{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414964aa-a1e6-4047-96b2-a14518a32a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a6e22-b510-4b89-bd4b-4c34a51edea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a306859-1c19-4189-9274-ff509bf48e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN = \"compositional_graphics\"\n",
    "\n",
    "EXPERIMENT_ID_BASELINE = \"logo_stitch_iterative\"\n",
    "EXPERIMENT_ID_CODEX = \"logo_codex_stitch_iterative_human_readable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f938f2-0cf5-4173-a9c8-1fc202aa6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_ITERATIVE_BASELINE = f\"../experiments/outputs/{DOMAIN}/{EXPERIMENT_ID_BASELINE}/\"\n",
    "DIR_ITERATIVE_CODEX = f\"../experiments/outputs/{DOMAIN}/{EXPERIMENT_ID_CODEX}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83708e60-7874-4922-a6fc-71331ead913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_likelihoods(dir_results):\n",
    "    data = []\n",
    "\n",
    "    for path in sorted(glob.glob(os.path.join(dir_results, \"*\"))):\n",
    "        config_json_path = os.path.join(path, \"config.json\")\n",
    "        with open(config_json_path, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        global_batch_size = config[\"experiment_iterator\"][\"task_batcher\"][\"params\"][\n",
    "            \"global_batch_size\"\n",
    "        ]\n",
    "\n",
    "        test_likelihoods_json_path = os.path.join(path, \"0\", \"test_likelihoods.json\")\n",
    "        with open(test_likelihoods_json_path, \"r\") as f:\n",
    "            likelihoods_data = json.load(f)\n",
    "\n",
    "        stitch_frontiers_json_path = os.path.join(\n",
    "            path, \"0\", \"train\", \"stitch_frontiers.json\"\n",
    "        )\n",
    "        with open(stitch_frontiers_json_path, \"r\") as f:\n",
    "            stitch_frontiers_data = json.load(f)\n",
    "\n",
    "        for task_name, ll_list in likelihoods_data[\"log_likelihoods_by_task\"][\n",
    "            \"test\"\n",
    "        ].items():\n",
    "            data.append(\n",
    "                {\n",
    "                    \"batch_size\": global_batch_size,\n",
    "                    \"task_name\": task_name,\n",
    "                    \"log_likelihood\": ll_list[0],\n",
    "                    \"n_frontiers\": len(stitch_frontiers_data[\"frontiers\"]),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d595f-1bcd-4945-99c3-f5979bc49ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = get_log_likelihoods(DIR_ITERATIVE_BASELINE)\n",
    "df1[\"condition\"] = \"Stitch\"\n",
    "\n",
    "df2 = None\n",
    "\n",
    "df2 = get_log_likelihoods(DIR_ITERATIVE_CODEX)\n",
    "df2[\"condition\"] = \"Stitch + Codex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6e017-cabb-487f-b2a9-60a259966502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], axis=0).reset_index(drop=True)\n",
    "BATCH_SIZES = sorted(df.batch_size.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a54f536-d358-4bd9-8298-27353fab6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6bb96-5b8b-4b39-913c-e2a1c4d32923",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=df, x=\"batch_size\", y=\"log_likelihood\", hue=\"condition\")\n",
    "g.set(xscale=\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bcec30-c41f-4719-b8c2-8347cbc9b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(data=df, x=\"batch_size\", y=\"log_likelihood\", hue=\"condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45621240-02f7-40c2-9ac1-0bcbbc27776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(data=df, x=\"batch_size\", y=\"n_frontiers\", hue=\"condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da8384-b5c9-4231-b9f3-1cfe9f194277",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(data=df, x=\"n_frontiers\", y=\"log_likelihood\", hue=\"condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba3a95-ef44-422b-b1e9-a270e3fb6349",
   "metadata": {},
   "source": [
    "## What programs does Codex generate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29840256-240b-4637-88d3-25a272b6260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "codex_query_results_json_paths = glob.glob(\n",
    "    f\"../experiments/outputs/{DOMAIN}/{EXPERIMENT_ID_CODEX}/{EXPERIMENT_ID_CODEX}_*/0/codex_query_results.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43f3e8-db48-487f-9ae6-342d9527383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codex_programs():\n",
    "    df_list = []\n",
    "    for batch_size in BATCH_SIZES:\n",
    "        path = f\"../experiments/outputs/{DOMAIN}/{EXPERIMENT_ID_CODEX}/{EXPERIMENT_ID_CODEX}_{batch_size}/0/codex_query_results.json\"\n",
    "        with open(path, \"r\") as f:\n",
    "            codex_query_results = json.load(f)\n",
    "\n",
    "        data = []\n",
    "        for p in codex_query_results[\"prompt_programs\"]:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"program\": p,\n",
    "                    \"origin\": \"train\",\n",
    "                    \"valid\": True,\n",
    "                }\n",
    "            )\n",
    "        for p in codex_query_results[\"programs_valid\"]:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"program\": p,\n",
    "                    \"origin\": \"codex\",\n",
    "                    \"valid\": True,\n",
    "                }\n",
    "            )\n",
    "        for p in codex_query_results[\"programs_invalid\"]:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"program\": p,\n",
    "                    \"origin\": \"codex\",\n",
    "                    \"valid\": False,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df[\"program_str_len\"] = df.program.str.len()\n",
    "        df[\"batch_size\"] = batch_size\n",
    "\n",
    "        train_programs = set(df[df[\"origin\"] == \"train\"][\"program\"])\n",
    "        df[\"copied_from_train\"] = [(row[\"origin\"] == \"codex\") and (row[\"program\"] in train_programs) for _, row in df.iterrows()]\n",
    "        \n",
    "        df_list.append(df)\n",
    "\n",
    "#         print(\n",
    "#             f\"+ From {batch_size} training programs, Codex generated {len(df[df.origin == 'codex'])} programs, for a total of {len(df)} programs.\"\n",
    "#         )\n",
    "#         print(\n",
    "#             f\"+ Of these, {len(df[(df.origin == 'codex') & (df.valid)])} were valid and {len(df[(df.origin == 'codex') & (~df.valid)])} were invalid.\"\n",
    "#         )\n",
    "#         print(\n",
    "#             f\"+ In total, there were {df['program'].nunique()} unique programs; {df[df.valid]['program'].nunique()} were valid.\"\n",
    "#         )\n",
    "\n",
    "#         copied_programs = set(codex_query_results[\"programs_valid\"]) & set(\n",
    "#             codex_query_results[\"prompt_programs\"]\n",
    "#         )\n",
    "#         print(\n",
    "#             f\"+ {len(copied_programs)} of the Codex programs were direct copies from the training data.\"\n",
    "#         )\n",
    "        \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdcfd3-28df-4eb6-abbc-6c75805348b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = get_codex_programs()\n",
    "df_codex = pd.concat(df_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12b303-54aa-41a5-9aab-f79da6043604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b9d6c-00d6-422f-a3eb-6918f6f080b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Percentage of valid programs\")\n",
    "sns.pointplot(data=df_codex, x=\"batch_size\", y=\"valid\", hue=\"origin\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba478f5-1bee-4908-8084-fd3b49f34a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Program string length\")\n",
    "sns.violinplot(data=df_codex, x=\"batch_size\", y=\"program_str_len\", hue=\"origin\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa53ff0-bbc4-4981-b5b9-85a20b5eac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Count of unique programs\")\n",
    "sns.pointplot(data=df_codex.groupby(\"batch_size\").nunique().reset_index(), x=\"batch_size\", y=\"program\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf90fd-5fd3-4183-acb5-6914d29d1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Count of programs copied from train\")\n",
    "sns.pointplot(data=df_codex.groupby(\"batch_size\").sum().reset_index(), x=\"batch_size\", y=\"copied_from_train\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce971eba-afc7-4f63-908f-aa6533e8f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_codex, x=\"program_str_len\", hue=\"valid\", col=\"origin\", row=\"batch_size\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca788987-21c2-4d0c-8550-d650f27a8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.program[df.origin == \"train\"].tolist()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f41f18-086b-4969-813c-ef24f3cf95d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.program[df.origin == \"codex\"].tolist()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cbc8d2-26a3-4db2-8245-898358689691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ac494-ea7f-4287-84a6-1d107044505e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
