{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed51a4f-2576-4717-97e1-784d69d040a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414964aa-a1e6-4047-96b2-a14518a32a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a6e22-b510-4b89-bd4b-4c34a51edea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd9f19-1ce5-4953-a80c-3f6e6fb42510",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIR = \"../experiments_iterative\"\n",
    "DOMAINS_DIR = \"domains\"\n",
    "\n",
    "COMPUTE_LIKELIHOODS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a306859-1c19-4189-9274-ff509bf48e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laps domains\n",
    "# DOMAIN = \"logo\"\n",
    "# DOMAIN = \"clevr\"\n",
    "# DOMAIN = \"re2\"\n",
    "\n",
    "# drawings domains\n",
    "DOMAIN = \"drawings_nuts_bolts\"\n",
    "# DOMAIN = \"drawings_furniture\"\n",
    "# DOMAIN = \"drawings_dials\"\n",
    "# DOMAIN = \"drawings_wheels\"\n",
    "\n",
    "CONDITION_STITCH = \"stitch\"\n",
    "CONDITION_STITCH_CODEX = \"stitch_codex\"\n",
    "CONDITION_STITCH_CODEX_LANGUAGE = \"stitch_codex_language\"\n",
    "CONDITION_ORACLE = \"oracle\"\n",
    "CONDITION_ORACLE_TRAIN_TEST = \"oracle_train_test\"\n",
    "\n",
    "RANDOM_SEEDS = []\n",
    "# RANDOM_SEEDS = [111]\n",
    "\n",
    "# ERROR_BAR_COL = \"task_name\"  # Error bars will show variation across tasks; results from different random seeds will be averaged\n",
    "ERROR_BAR_COL = \"random_seed\" # Error bars will show variation across random seeds; results from different tasks will be averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b118f8-3b01-431e-919a-3b41a2112698",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(DOMAINS_DIR, DOMAIN), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a3877-1564-476a-b3d6-2119944fa2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_SORT = lambda x: (len(x), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83708e60-7874-4922-a6fc-71331ead913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_likelihoods(condition, split):\n",
    "    results_pattern = os.path.join(\n",
    "        EXPERIMENT_DIR, \"outputs\", \"domains\", DOMAIN, condition, f\"seed_*\"\n",
    "    )\n",
    "\n",
    "    seed_paths = sorted(glob.glob(results_pattern), key=NUMERIC_SORT)\n",
    "    if not seed_paths:\n",
    "        raise ValueError(results_pattern)\n",
    "\n",
    "    df_list = []\n",
    "    for seed_path in seed_paths:\n",
    "        random_seed = int(seed_path[len(results_pattern) - 1 :])\n",
    "\n",
    "        if len(RANDOM_SEEDS) > 0 and random_seed not in RANDOM_SEEDS:\n",
    "            continue\n",
    "\n",
    "        print(f\"Condition: {condition}, split: {split}, seed: {random_seed}\")\n",
    "\n",
    "        df = get_log_likelihoods_single_replication(condition, split, random_seed)\n",
    "        df[\"random_seed\"] = random_seed\n",
    "        df_list.append(df)\n",
    "\n",
    "    df_concat = pd.concat(df_list, axis=0).reset_index(drop=True)\n",
    "\n",
    "    # Compute the mean over replications\n",
    "    AGG_COLS = [\"n_frontiers\", \"description_length\"]\n",
    "    if COMPUTE_LIKELIHOODS:\n",
    "        AGG_COLS += [\"log_likelihood\"]\n",
    "    df_out = df_concat.groupby(\n",
    "        [\"batch_size\", ERROR_BAR_COL], sort=False, as_index=False\n",
    "    )[AGG_COLS].mean()\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def get_log_likelihoods_single_replication(condition, split, random_seed):\n",
    "    data = []\n",
    "\n",
    "    results_pattern = os.path.join(\n",
    "        EXPERIMENT_DIR,\n",
    "        \"outputs\",\n",
    "        \"domains\",\n",
    "        DOMAIN,\n",
    "        condition,\n",
    "        f\"seed_{random_seed}\",\n",
    "        f\"{condition}_*\",\n",
    "    )\n",
    "\n",
    "    for path in sorted(glob.glob(results_pattern), key=NUMERIC_SORT):\n",
    "        config_json_path = os.path.join(path, \"config.json\")\n",
    "        if not os.path.exists(config_json_path):\n",
    "            continue\n",
    "        with open(config_json_path, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        global_batch_size = config[\"experiment_iterator\"][\"task_batcher\"][\"params\"][\n",
    "            \"global_batch_size\"\n",
    "        ]\n",
    "\n",
    "        test_likelihoods_json_path = os.path.join(path, \"0\", \"test_likelihoods.json\")\n",
    "        if not os.path.exists(test_likelihoods_json_path):\n",
    "            continue\n",
    "        with open(test_likelihoods_json_path, \"r\") as f:\n",
    "            likelihoods_data = json.load(f)\n",
    "\n",
    "        stitch_frontiers_json_path = os.path.join(\n",
    "            path, \"0\", split, \"stitch_frontiers.json\"\n",
    "        )\n",
    "        if not os.path.exists(stitch_frontiers_json_path):\n",
    "            continue\n",
    "        with open(stitch_frontiers_json_path, \"r\") as f:\n",
    "            stitch_frontiers_data = json.load(f)\n",
    "\n",
    "        for task_name, dl_list in likelihoods_data[\"description_lengths_by_task\"][\n",
    "            \"test\"\n",
    "        ].items():\n",
    "            d = {\n",
    "                \"batch_size\": global_batch_size,\n",
    "                \"task_name\": task_name,\n",
    "                \"description_length\": dl_list[0],\n",
    "                \"n_frontiers\": len(stitch_frontiers_data[\"frontiers\"]),\n",
    "            }\n",
    "            if COMPUTE_LIKELIHOODS:\n",
    "                d[\"log_likelihood\"] = likelihoods_data[\"log_likelihoods_by_task\"][\n",
    "                    \"test\"\n",
    "                ][task_name][0]\n",
    "\n",
    "            data.append(d)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d595f-1bcd-4945-99c3-f5979bc49ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stitch = get_log_likelihoods(CONDITION_STITCH, \"train\")\n",
    "df_stitch[\"condition\"] = \"Stitch\"\n",
    "\n",
    "df_stitch_codex = get_log_likelihoods(CONDITION_STITCH_CODEX, \"train\")\n",
    "df_stitch_codex[\"condition\"] = \"Stitch + Codex\"\n",
    "\n",
    "df_stitch_codex_language = get_log_likelihoods(CONDITION_STITCH_CODEX_LANGUAGE, \"train\")\n",
    "df_stitch_codex_language[\"condition\"] = \"Stitch + Codex + Language\"\n",
    "df_stitch_codex_language[\"language\"] = True\n",
    "\n",
    "df_oracle = get_log_likelihoods(CONDITION_ORACLE, \"test\")\n",
    "df_oracle[\"condition\"] = \"Oracle (Test)\"\n",
    "\n",
    "df_oracle_train_test = get_log_likelihoods(CONDITION_ORACLE_TRAIN_TEST, \"train_test\")\n",
    "df_oracle_train_test[\"condition\"] = \"Oracle (Train + Test)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6e017-cabb-487f-b2a9-60a259966502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_stitch, df_stitch_codex, df_stitch_codex_language, df_oracle, df_oracle_train_test], axis=0).reset_index(drop=True)\n",
    "df.batch_size = df.batch_size.astype(int)\n",
    "BATCH_SIZES = sorted(df.batch_size.unique().tolist())\n",
    "BATCH_SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcea9dc-de27-4df4-9100-87768c77a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45621240-02f7-40c2-9ac1-0bcbbc27776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(DOMAIN);\n",
    "sns.barplot(data=df, x=\"batch_size\", y=\"n_frontiers\", hue=\"condition\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d95d367-5446-45e1-81cc-592530b6fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(DOMAIN);\n",
    "sns.pointplot(data=df, x=\"batch_size\", y=\"description_length\", hue=\"condition\");\n",
    "plt.savefig(os.path.join(DOMAINS_DIR, DOMAIN, f\"description_length.png\"), dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae355f77-0202-4e41-a895-ebfa294cd0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(DOMAIN);\n",
    "g = sns.lineplot(data=df, x=\"batch_size\", y=\"description_length\", hue=\"condition\")\n",
    "g.set(xscale=\"log\");\n",
    "plt.savefig(os.path.join(DOMAINS_DIR, DOMAIN, f\"description_length_logscale.png\"), dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bcec30-c41f-4719-b8c2-8347cbc9b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_LIKELIHOODS:\n",
    "    plt.title(DOMAIN);\n",
    "    sns.pointplot(data=df, x=\"batch_size\", y=\"log_likelihood\", hue=\"condition\")\n",
    "    plt.savefig(os.path.join(DOMAINS_DIR, DOMAIN, f\"likelihood.png\"), dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6bb96-5b8b-4b39-913c-e2a1c4d32923",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_LIKELIHOODS:\n",
    "    plt.title(DOMAIN);\n",
    "    g = sns.lineplot(data=df, x=\"batch_size\", y=\"log_likelihood\", hue=\"condition\")\n",
    "    g.set(xscale=\"log\");\n",
    "    plt.savefig(os.path.join(DOMAINS_DIR, DOMAIN, f\"likelihood_logscale.png\"), dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d0040-5208-41ec-8923-5e13b08c2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_LIKELIHOODS:\n",
    "    plt.title(DOMAIN);\n",
    "    sns.scatterplot(\n",
    "        data=df, x=\"description_length\", y=\"log_likelihood\", hue=\"condition\", alpha=0.25\n",
    "    )\n",
    "    plt.savefig(os.path.join(DOMAINS_DIR, DOMAIN, f\"description_length_vs_likelihood.png\"), dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba3a95-ef44-422b-b1e9-a270e3fb6349",
   "metadata": {},
   "source": [
    "# What programs does Codex generate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43f3e8-db48-487f-9ae6-342d9527383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codex_programs():\n",
    "    results_pattern = os.path.join(\n",
    "        EXPERIMENT_DIR, \"outputs\", \"domains\", DOMAIN, CONDITION_STITCH_CODEX, f\"seed_*\"\n",
    "    )\n",
    "    seed_paths = sorted(glob.glob(results_pattern), key=NUMERIC_SORT)\n",
    "    if not seed_paths:\n",
    "        raise ValueError(results_pattern)\n",
    "    print(seed_paths)\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for seed_path in seed_paths:\n",
    "        random_seed = int(seed_path[len(results_pattern) - 1 :])\n",
    "\n",
    "        for batch_size in BATCH_SIZES:\n",
    "            path = os.path.join(\n",
    "                seed_path,\n",
    "                f\"{CONDITION_STITCH_CODEX}_{batch_size}/0/codex_query_results.json\",\n",
    "            )\n",
    "            \n",
    "            if not os.path.exists(path):\n",
    "                print(f\"Skipped nonexisten {path}\")\n",
    "                continue\n",
    "\n",
    "            with open(path, \"r\") as f:\n",
    "                codex_query_results = json.load(f)\n",
    "\n",
    "            data = []\n",
    "            for query_data in codex_query_results[\"results_by_query\"]:\n",
    "                for body_task_data in query_data[\"prompt\"][\"body_task_data\"]:\n",
    "                    body_task_data[\"query_id\"] = query_data[\"query_id\"]\n",
    "                    body_task_data[\"program\"] = body_task_data[\"task_program\"]\n",
    "                    body_task_data.pop(\"task_program\")\n",
    "                    body_task_data[\"origin\"] = \"train\"\n",
    "                    body_task_data[\"final_task\"] = False\n",
    "                    body_task_data[\"valid\"] = True\n",
    "                    body_task_data[\"seed\"] = random_seed\n",
    "                    data.append(body_task_data)\n",
    "                \n",
    "                if \"programs\" in codex_query_results[\"params\"][\"final_task_types\"]:\n",
    "                    final_task_data = query_data[\"prompt\"][\"final_task_data\"]\n",
    "                    final_task_data[\"query_id\"] = query_data[\"query_id\"]\n",
    "                    final_task_data[\"program\"] = \"task_program\"\n",
    "                    final_task_data.pop(\"task_program\")\n",
    "                    final_task_data[\"origin\"] = \"train\"\n",
    "                    final_task_data[\"final_task\"] = True\n",
    "                    final_task_data[\"valid\"] = True\n",
    "                    final_task_data[\"seed\"] = random_seed\n",
    "                    data.append(final_task_data)\n",
    "                    \n",
    "                for parse_result_data in query_data[\"parse_results\"]:\n",
    "                    parse_result_data[\"origin\"] = \"codex\"\n",
    "                    parse_result_data[\"final_task\"] = False\n",
    "                    parse_result_data[\"seed\"] = random_seed\n",
    "                    if not parse_result_data[\"valid\"]:\n",
    "                        parse_result_data[\"program\"] = parse_result_data[\"text\"]\n",
    "                    data.append(parse_result_data)\n",
    "\n",
    "\n",
    "            df = pd.DataFrame(data)\n",
    "            df[\"program_str_len\"] = df.program.str.len()\n",
    "            df[\"batch_size\"] = batch_size\n",
    "            df[\"random_seed\"] = random_seed\n",
    "\n",
    "            tps = df[df[\"origin\"] == \"train\"][\"program\"]\n",
    "\n",
    "            train_programs = set(df[df[\"origin\"] == \"train\"][\"program\"].tolist())\n",
    "            df[\"copied_from_train\"] = [\n",
    "                (row[\"origin\"] == \"codex\") and (row[\"program\"] in train_programs)\n",
    "                for _, row in df.iterrows()\n",
    "            ]\n",
    "\n",
    "            df_list.append(df)\n",
    "\n",
    "    return pd.concat(df_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdcfd3-28df-4eb6-abbc-6c75805348b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codex = get_codex_programs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12b303-54aa-41a5-9aab-f79da6043604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b9d6c-00d6-422f-a3eb-6918f6f080b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Percentage of valid programs\")\n",
    "sns.barplot(data=df_codex, x=\"batch_size\", y=\"valid\", hue=\"origin\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba478f5-1bee-4908-8084-fd3b49f34a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Program string length\")\n",
    "sns.violinplot(data=df_codex, x=\"batch_size\", y=\"program_str_len\", hue=\"origin\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa53ff0-bbc4-4981-b5b9-85a20b5eac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Count of unique programs\")\n",
    "\n",
    "df_tmp1 = df_codex.query(\"origin == 'train'\").groupby([\"batch_size\", \"seed\"]).nunique().reset_index()\n",
    "df_tmp2 = df_codex.query(\"origin == 'codex'\").groupby([\"batch_size\", \"seed\"]).nunique().reset_index()\n",
    "df_tmp3 = df_codex.query(\"origin == 'codex' & copied_from_train\").groupby([\"batch_size\", \"seed\"]).nunique().reset_index()\n",
    "df_tmp4 = df_codex.query(\"origin == 'codex' & ~copied_from_train\").groupby([\"batch_size\", \"seed\"]).nunique().reset_index()\n",
    "df_tmp1[\"origin\"] = \"train\"\n",
    "df_tmp2[\"origin\"] = \"codex (overall)\"\n",
    "df_tmp3[\"origin\"] = \"codex (copied from train)\"\n",
    "df_tmp4[\"origin\"] = \"codex (original)\"\n",
    "\n",
    "df_tmp = pd.concat([df_tmp1, df_tmp2, df_tmp3, df_tmp4], axis=0).reset_index()\n",
    "\n",
    "sns.pointplot(data=df_tmp, x=\"batch_size\", y=\"program\", hue=\"origin\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf90fd-5fd3-4183-acb5-6914d29d1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Count of programs copied from train\")\n",
    "sns.pointplot(\n",
    "    data=df_codex.groupby([\"batch_size\", \"seed\"]).sum().reset_index(),\n",
    "    x=\"batch_size\",\n",
    "    y=\"copied_from_train\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1f26d-d6a3-45bc-aa35-2b6cffef55b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codex[\"valid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce971eba-afc7-4f63-908f-aa6533e8f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This plot takes a while to render\n",
    "\n",
    "# sns.displot(\n",
    "#     data=df_codex, x=\"program_str_len\", hue=\"valid\", col=\"origin\", row=\"batch_size\"\n",
    "# );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2dbd18-7992-4268-b573-12b6bddad272",
   "metadata": {},
   "source": [
    "# What inventions are in the libraries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab9d019-c89b-4b01-b006-61db4e7717b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_library_inventions(condition, split, seed):\n",
    "    data = []\n",
    "    for batch_size in BATCH_SIZES:\n",
    "        path = os.path.join(\n",
    "            EXPERIMENT_DIR,\n",
    "            \"outputs\",\n",
    "            \"domains\",\n",
    "            DOMAIN,\n",
    "            condition,\n",
    "            f\"seed_{seed}\",\n",
    "            f\"{condition}_{batch_size}\",\n",
    "            \"0\",\n",
    "            split,\n",
    "            \"stitch_output.json\",\n",
    "        )\n",
    "        # path = f\"../experiments/outputs/{DOMAIN}/{experiment_id}/{experiment_id}_{batch_size}/0/{split}/stitch_output.json\"\n",
    "\n",
    "        with open(path, \"r\") as f:\n",
    "            stitch_output_data = json.load(f)\n",
    "\n",
    "        df = pd.DataFrame(stitch_output_data[\"invs\"])[\n",
    "            [\"name\", \"arity\", \"utility\", \"multiplier\", \"body\", \"dreamcoder\"]\n",
    "        ]\n",
    "        df[\"batch_size\"] = batch_size\n",
    "        data.append(df)\n",
    "\n",
    "    return pd.concat(data, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3b288-1db5-400f-9bd1-30ac73d59b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_BASELINE = 111\n",
    "SEED_CODEX = 111\n",
    "\n",
    "df_libraries_baseline = get_library_inventions(CONDITION_STITCH, \"train\", seed=SEED_BASELINE)\n",
    "df_libraries_baseline[\"condition\"] = \"baseline\"\n",
    "\n",
    "df_libraries_codex = get_library_inventions(CONDITION_STITCH_CODEX, \"train\", seed=SEED_CODEX)\n",
    "df_libraries_codex[\"condition\"] = \"codex\"\n",
    "\n",
    "df_libraries_test = get_library_inventions(CONDITION_ORACLE, \"test\", seed=SEED_BASELINE)\n",
    "df_libraries_test[\"condition\"] = \"test\"\n",
    "\n",
    "df_libraries = pd.concat(\n",
    "    [df_libraries_baseline, df_libraries_codex, df_libraries_test], axis=0\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68aca0-86d4-4b4d-b0af-93385e631144",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overlap = []\n",
    "for batch_size, group in df_libraries.groupby(\"batch_size\"):\n",
    "    fns_baseline = set(group[group.condition == \"baseline\"].dreamcoder)\n",
    "    fns_codex = set(group[group.condition == \"codex\"].dreamcoder)\n",
    "    fns_test = set(group[group.condition == \"test\"].dreamcoder)\n",
    "    data_overlap.append(\n",
    "        {\n",
    "            \"batch_size\": int(batch_size),\n",
    "            \"utility_baseline\": group[group.condition == \"baseline\"][\"utility\"].sum(),\n",
    "            \"utility_codex\": group[group.condition == \"codex\"][\"utility\"].sum(),\n",
    "            \"utility_test\": group[group.condition == \"test\"][\"utility\"].sum(),\n",
    "            \"n_baseline\": len(fns_baseline),\n",
    "            \"fns_baseline\": fns_baseline,\n",
    "            \"n_codex\": len(fns_codex),\n",
    "            \"fns_codex\": fns_codex,\n",
    "            \"n_test\": len(fns_test),\n",
    "            \"fns_test\": fns_test,\n",
    "            \"n_baseline_only\": len(fns_baseline - fns_codex),\n",
    "            \"fns_baseline_only\": fns_baseline - fns_codex,\n",
    "            \"n_codex_only\": len(fns_codex - fns_baseline),\n",
    "            \"fns_codex_only\": fns_codex - fns_baseline,\n",
    "            \"n_overlap\": len(fns_baseline & fns_codex),\n",
    "            \"fns_overlap\": (fns_baseline & fns_codex),\n",
    "            \"n_baseline_test\": len(fns_baseline & fns_test),\n",
    "            \"n_codex_test\": len(fns_codex & fns_test),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f6e69-06fa-48eb-965b-fcf859d21d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = pd.DataFrame(data_overlap)\n",
    "df_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a25ff-d713-4f5b-b1ca-3d7940d52e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap_long = df_overlap.rename(\n",
    "    dict(\n",
    "        zip(\n",
    "            [\"n_baseline_only\", \"n_codex_only\", \"n_overlap\"],\n",
    "            [\"baseline_only\", \"codex_only\", \"overlap\"],\n",
    "        )\n",
    "    ),\n",
    "    axis=\"columns\",\n",
    ")\n",
    "df_overlap_long = df_overlap_long.melt(\n",
    "    id_vars=\"batch_size\",\n",
    "    value_vars=[\"baseline_only\", \"codex_only\", \"overlap\"],\n",
    "    var_name=\"library\",\n",
    "    value_name=\"Inventions (count)\",\n",
    ")\n",
    "\n",
    "plt.title(\"Overlap between Baseline and Codex inventions\")\n",
    "sns.barplot(data=df_overlap_long, x=\"batch_size\", y=\"Inventions (count)\", hue=\"library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a0bb48-ae7d-4aab-83ec-de1e032d1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap_long = df_overlap.rename(\n",
    "    dict(\n",
    "        zip(\n",
    "            [\"n_baseline_test\", \"n_codex_test\", \"n_test\"],\n",
    "            [\"Stitch\", \"Stitch + Codex\", \"Oracle\"],\n",
    "        )\n",
    "    ),\n",
    "    axis=\"columns\",\n",
    ")\n",
    "df_overlap_long = df_overlap_long.melt(\n",
    "    id_vars=\"batch_size\",\n",
    "    value_vars=[\"Stitch\", \"Stitch + Codex\", \"Oracle\"],\n",
    "    var_name=\"library\",\n",
    "    value_name=\"Oracle inventions discovered (count)\",\n",
    ")\n",
    "\n",
    "plt.title(\"Discovery of oracle (test set) inventions\")\n",
    "sns.pointplot(\n",
    "    data=df_overlap_long,\n",
    "    x=\"batch_size\",\n",
    "    y=\"Oracle inventions discovered (count)\",\n",
    "    hue=\"library\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db007501-a15c-4aa2-8a8a-b9b525ca8cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8187b15-10e4-40b6-ab2d-c28a3c27f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn2, venn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6558d-60db-4489-9587-370861d42bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"library_venn_diagrams\", exist_ok=True)\n",
    "os.makedirs(\"library_venn_diagrams/venn2\", exist_ok=True)\n",
    "os.makedirs(\"library_venn_diagrams/venn3\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e248f1a-d918-492f-8572-2aa129bcb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_overlap.iterrows():\n",
    "    plt.figure()\n",
    "    venn2(\n",
    "        subsets=(row[\"n_baseline_only\"], row[\"n_codex_only\"], row[\"n_overlap\"]),\n",
    "        set_labels=(\"Baseline\", \"Codex\"),\n",
    "    )\n",
    "    plt.title(\"Batch size: \" + str(row[\"batch_size\"]))\n",
    "    plt.savefig(\n",
    "        f\"library_venn_diagrams/venn2/batch_{row['batch_size']:03d}.png\", dpi=144\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79c83ca-8969-43ba-82f4-386676fbbed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size, group in df_libraries.groupby(\"batch_size\"):\n",
    "    fns_baseline = set(group[group.condition == \"baseline\"].dreamcoder)\n",
    "    fns_codex = set(group[group.condition == \"codex\"].dreamcoder)\n",
    "    fns_test = set(group[group.condition == \"test\"].dreamcoder)\n",
    "    plt.figure()\n",
    "    venn3(\n",
    "        [fns_baseline, fns_codex, fns_test],\n",
    "        set_labels=(\"Baseline\", \"Codex\", \"Oracle\"),\n",
    "    )\n",
    "    plt.title(\"Batch size: \" + str(batch_size))\n",
    "    plt.savefig(f\"library_venn_diagrams/venn3/batch_{int(batch_size):03d}.png\", dpi=144)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
