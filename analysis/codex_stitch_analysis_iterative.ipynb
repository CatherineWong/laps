{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed51a4f-2576-4717-97e1-784d69d040a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414964aa-a1e6-4047-96b2-a14518a32a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a6e22-b510-4b89-bd4b-4c34a51edea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd9f19-1ce5-4953-a80c-3f6e6fb42510",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIR = \"../experiments_iterative\"\n",
    "\n",
    "COMPUTE_LIKELIHOODS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a306859-1c19-4189-9274-ff509bf48e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN = \"logo\"\n",
    "\n",
    "CONDITION_STITCH = \"stitch\"\n",
    "CONDITION_STITCH_CODEX = \"stitch_codex\"\n",
    "CONDITION_ORACLE = \"oracle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a3877-1564-476a-b3d6-2119944fa2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_SORT = lambda x: (len(x), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83708e60-7874-4922-a6fc-71331ead913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_likelihoods(condition, split):\n",
    "    results_pattern = os.path.join(EXPERIMENT_DIR, \"outputs\", \"domains\", DOMAIN, condition, f\"seed_*\")\n",
    "    \n",
    "    seed_paths = sorted(glob.glob(results_pattern), key=NUMERIC_SORT)    \n",
    "    if not seed_paths:\n",
    "        raise ValueError(results_pattern)\n",
    "    \n",
    "    df_list = []\n",
    "    for seed_path in seed_paths:\n",
    "        random_seed = int(seed_path[len(results_pattern)-1:])\n",
    "        print(f\"Condition: {condition}, split: {split}, seed: {random_seed}\")\n",
    "        \n",
    "        df = get_log_likelihoods_single_replication(condition, split, random_seed)\n",
    "        df[\"random_seed\"] = random_seed\n",
    "        df_list.append(df)\n",
    "        \n",
    "    df_concat = pd.concat(df_list, axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Compute the mean over replications\n",
    "    AGG_COLS = [\"n_frontiers\", \"description_length\"]\n",
    "    if COMPUTE_LIKELIHOODS:\n",
    "        AGG_COLS += [\"log_likelihood\"]\n",
    "    df_out = df_concat.groupby([\"batch_size\", \"task_name\"], sort=False, as_index=False)[AGG_COLS].mean()\n",
    "    \n",
    "    return df_out\n",
    "    \n",
    "\n",
    "def get_log_likelihoods_single_replication(condition, split, random_seed):\n",
    "    data = []\n",
    "    \n",
    "    results_pattern = os.path.join(EXPERIMENT_DIR, \"outputs\", \"domains\", DOMAIN, condition, f\"seed_{random_seed}\", f\"{condition}_*\")\n",
    "\n",
    "    for path in sorted(glob.glob(results_pattern), key=NUMERIC_SORT):\n",
    "        config_json_path = os.path.join(path, \"config.json\")\n",
    "        with open(config_json_path, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        global_batch_size = config[\"experiment_iterator\"][\"task_batcher\"][\"params\"][\n",
    "            \"global_batch_size\"\n",
    "        ]\n",
    "\n",
    "        test_likelihoods_json_path = os.path.join(path, \"0\", \"test_likelihoods.json\")\n",
    "        with open(test_likelihoods_json_path, \"r\") as f:\n",
    "            likelihoods_data = json.load(f)\n",
    "\n",
    "        stitch_frontiers_json_path = os.path.join(\n",
    "            path, \"0\", split, \"stitch_frontiers.json\"\n",
    "        )\n",
    "        with open(stitch_frontiers_json_path, \"r\") as f:\n",
    "            stitch_frontiers_data = json.load(f)\n",
    "\n",
    "        for task_name, dl_list in likelihoods_data[\"description_lengths_by_task\"][\n",
    "            \"test\"\n",
    "        ].items():\n",
    "            d = {\n",
    "                    \"batch_size\": global_batch_size,\n",
    "                    \"task_name\": task_name,\n",
    "                    \"description_length\": dl_list[0],\n",
    "                    \"n_frontiers\": len(stitch_frontiers_data[\"frontiers\"]),\n",
    "                }\n",
    "            if COMPUTE_LIKELIHOODS:\n",
    "                d[\"log_likelihood\"] = likelihoods_data[\"log_likelihoods_by_task\"][\"test\"][task_name][0]\n",
    "                \n",
    "            data.append(d)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d595f-1bcd-4945-99c3-f5979bc49ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = get_log_likelihoods(CONDITION_STITCH, \"train\")\n",
    "df1[\"condition\"] = \"Stitch\"\n",
    "\n",
    "df2 = get_log_likelihoods(CONDITION_STITCH_CODEX, \"train\")\n",
    "df2[\"condition\"] = \"Stitch + Codex\"\n",
    "\n",
    "df3 = get_log_likelihoods(CONDITION_ORACLE, \"test\")\n",
    "df3[\"condition\"] = \"Oracle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6e017-cabb-487f-b2a9-60a259966502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3], axis=0).reset_index(drop=True)\n",
    "df.batch_size = df.batch_size.astype(int)\n",
    "BATCH_SIZES = sorted(df.batch_size.unique().tolist())\n",
    "BATCH_SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcea9dc-de27-4df4-9100-87768c77a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45621240-02f7-40c2-9ac1-0bcbbc27776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df, x=\"batch_size\", y=\"n_frontiers\", hue=\"condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d95d367-5446-45e1-81cc-592530b6fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(data=df, x=\"batch_size\", y=\"description_length\", hue=\"condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae355f77-0202-4e41-a895-ebfa294cd0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=df, x=\"batch_size\", y=\"description_length\", hue=\"condition\")\n",
    "g.set(xscale=\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bcec30-c41f-4719-b8c2-8347cbc9b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_LIKELIHOODS:\n",
    "    sns.pointplot(data=df, x=\"batch_size\", y=\"log_likelihood\", hue=\"condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6bb96-5b8b-4b39-913c-e2a1c4d32923",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_LIKELIHOODS:\n",
    "    g = sns.lineplot(data=df, x=\"batch_size\", y=\"log_likelihood\", hue=\"condition\")\n",
    "    g.set(xscale=\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d0040-5208-41ec-8923-5e13b08c2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_LIKELIHOODS:\n",
    "    sns.scatterplot(data=df, x=\"description_length\", y=\"log_likelihood\", hue=\"condition\", alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba3a95-ef44-422b-b1e9-a270e3fb6349",
   "metadata": {},
   "source": [
    "# What programs does Codex generate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43f3e8-db48-487f-9ae6-342d9527383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codex_programs():\n",
    "    df_list = []\n",
    "    for batch_size in BATCH_SIZES:\n",
    "        path = os.path.join(EXPERIMENT_DIR, \"outputs\", \"domains\", DOMAIN, CONDITION_STITCH_CODEX, f\"{CONDITION_STITCH_CODEX}_{batch_size}/0/codex_query_results.json\")\n",
    "        with open(path, \"r\") as f:\n",
    "            codex_query_results = json.load(f)\n",
    "\n",
    "        data = []\n",
    "        for p in codex_query_results[\"prompt_programs\"]:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"program\": p,\n",
    "                    \"origin\": \"train\",\n",
    "                    \"valid\": True,\n",
    "                }\n",
    "            )\n",
    "        for p in codex_query_results[\"programs_valid\"]:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"program\": p,\n",
    "                    \"origin\": \"codex\",\n",
    "                    \"valid\": True,\n",
    "                }\n",
    "            )\n",
    "        for p in codex_query_results[\"programs_invalid\"]:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"program\": p,\n",
    "                    \"origin\": \"codex\",\n",
    "                    \"valid\": False,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df[\"program_str_len\"] = df.program.str.len()\n",
    "        df[\"batch_size\"] = batch_size\n",
    "\n",
    "        train_programs = set(df[df[\"origin\"] == \"train\"][\"program\"])\n",
    "        df[\"copied_from_train\"] = [\n",
    "            (row[\"origin\"] == \"codex\") and (row[\"program\"] in train_programs)\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "        df_list.append(df)\n",
    "\n",
    "    #         print(\n",
    "    #             f\"+ From {batch_size} training programs, Codex generated {len(df[df.origin == 'codex'])} programs, for a total of {len(df)} programs.\"\n",
    "    #         )\n",
    "    #         print(\n",
    "    #             f\"+ Of these, {len(df[(df.origin == 'codex') & (df.valid)])} were valid and {len(df[(df.origin == 'codex') & (~df.valid)])} were invalid.\"\n",
    "    #         )\n",
    "    #         print(\n",
    "    #             f\"+ In total, there were {df['program'].nunique()} unique programs; {df[df.valid]['program'].nunique()} were valid.\"\n",
    "    #         )\n",
    "\n",
    "    #         copied_programs = set(codex_query_results[\"programs_valid\"]) & set(\n",
    "    #             codex_query_results[\"prompt_programs\"]\n",
    "    #         )\n",
    "    #         print(\n",
    "    #             f\"+ {len(copied_programs)} of the Codex programs were direct copies from the training data.\"\n",
    "    #         )\n",
    "\n",
    "    return pd.concat(df_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdcfd3-28df-4eb6-abbc-6c75805348b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codex = get_codex_programs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12b303-54aa-41a5-9aab-f79da6043604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b9d6c-00d6-422f-a3eb-6918f6f080b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Percentage of valid programs\")\n",
    "sns.barplot(data=df_codex, x=\"batch_size\", y=\"valid\", hue=\"origin\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba478f5-1bee-4908-8084-fd3b49f34a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Program string length\")\n",
    "sns.violinplot(data=df_codex, x=\"batch_size\", y=\"program_str_len\", hue=\"origin\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa53ff0-bbc4-4981-b5b9-85a20b5eac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Count of unique programs\")\n",
    "sns.pointplot(\n",
    "    data=df_codex.groupby(\"batch_size\").nunique().reset_index(),\n",
    "    x=\"batch_size\",\n",
    "    y=\"program\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf90fd-5fd3-4183-acb5-6914d29d1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Count of programs copied from train\")\n",
    "sns.pointplot(\n",
    "    data=df_codex.groupby(\"batch_size\").sum().reset_index(),\n",
    "    x=\"batch_size\",\n",
    "    y=\"copied_from_train\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce971eba-afc7-4f63-908f-aa6533e8f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    data=df_codex, x=\"program_str_len\", hue=\"valid\", col=\"origin\", row=\"batch_size\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2dbd18-7992-4268-b573-12b6bddad272",
   "metadata": {},
   "source": [
    "# What inventions are in the libraries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab9d019-c89b-4b01-b006-61db4e7717b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_library_inventions(condition, split):\n",
    "    data = []\n",
    "    for batch_size in BATCH_SIZES:\n",
    "        path = os.path.join(EXPERIMENT_DIR, \"outputs\", \"domains\", DOMAIN, condition, f\"{condition}_{batch_size}\", \"0\", split, \"stitch_output.json\")\n",
    "        # path = f\"../experiments/outputs/{DOMAIN}/{experiment_id}/{experiment_id}_{batch_size}/0/{split}/stitch_output.json\"\n",
    "\n",
    "        with open(path, \"r\") as f:\n",
    "            stitch_output_data = json.load(f)\n",
    "\n",
    "        df = pd.DataFrame(stitch_output_data[\"invs\"])[\n",
    "            [\"name\", \"arity\", \"utility\", \"multiplier\", \"body\", \"dreamcoder\"]\n",
    "        ]\n",
    "        df[\"batch_size\"] = batch_size\n",
    "        data.append(df)\n",
    "\n",
    "    return pd.concat(data, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3b288-1db5-400f-9bd1-30ac73d59b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_libraries_baseline = get_library_inventions(CONDITION_STITCH, \"train\")\n",
    "df_libraries_baseline[\"condition\"] = \"baseline\"\n",
    "\n",
    "df_libraries_codex = get_library_inventions(CONDITION_STITCH_CODEX, \"train\")\n",
    "df_libraries_codex[\"condition\"] = \"codex\"\n",
    "\n",
    "df_libraries_test = get_library_inventions(CONDITION_ORACLE, \"test\")\n",
    "df_libraries_test[\"condition\"] = \"test\"\n",
    "\n",
    "df_libraries = pd.concat(\n",
    "    [df_libraries_baseline, df_libraries_codex, df_libraries_test], axis=0\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68aca0-86d4-4b4d-b0af-93385e631144",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overlap = []\n",
    "for batch_size, group in df_libraries.groupby(\"batch_size\"):\n",
    "    fns_baseline = set(group[group.condition == \"baseline\"].dreamcoder)\n",
    "    fns_codex = set(group[group.condition == \"codex\"].dreamcoder)\n",
    "    fns_test = set(group[group.condition == \"test\"].dreamcoder)\n",
    "    data_overlap.append(\n",
    "        {\n",
    "            \"batch_size\": int(batch_size),\n",
    "            \"utility_baseline\": group[group.condition == \"baseline\"][\"utility\"].sum(),\n",
    "            \"utility_codex\": group[group.condition == \"codex\"][\"utility\"].sum(),\n",
    "            \"utility_test\": group[group.condition == \"test\"][\"utility\"].sum(),\n",
    "            \"n_baseline\": len(fns_baseline),\n",
    "            \"fns_baseline\": fns_baseline,\n",
    "            \"n_codex\": len(fns_codex),\n",
    "            \"fns_codex\": fns_codex,\n",
    "            \"n_test\": len(fns_test),\n",
    "            \"fns_test\": fns_test,\n",
    "            \"n_baseline_only\": len(fns_baseline - fns_codex),\n",
    "            \"fns_baseline_only\": fns_baseline - fns_codex,\n",
    "            \"n_codex_only\": len(fns_codex - fns_baseline),\n",
    "            \"fns_codex_only\": fns_codex - fns_baseline,\n",
    "            \"n_overlap\": len(fns_baseline & fns_codex),\n",
    "            \"fns_overlap\": (fns_baseline & fns_codex),\n",
    "            \"n_baseline_test\": len(fns_baseline & fns_test),\n",
    "            \"n_codex_test\": len(fns_codex & fns_test),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f6e69-06fa-48eb-965b-fcf859d21d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = pd.DataFrame(data_overlap)\n",
    "df_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a25ff-d713-4f5b-b1ca-3d7940d52e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap_long = df_overlap.rename(dict(zip([\"n_baseline_only\", \"n_codex_only\", \"n_overlap\"], [\"baseline_only\", \"codex_only\", \"overlap\"])), axis=\"columns\")\n",
    "df_overlap_long = df_overlap_long.melt(id_vars=\"batch_size\", value_vars=[\"baseline_only\", \"codex_only\", \"overlap\"], var_name=\"library\", value_name=\"Inventions (count)\")\n",
    "\n",
    "plt.title(\"Overlap between Baseline and Codex inventions\")\n",
    "sns.barplot(data=df_overlap_long, x=\"batch_size\", y=\"Inventions (count)\", hue=\"library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a0bb48-ae7d-4aab-83ec-de1e032d1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap_long = df_overlap.rename(dict(zip([\"n_baseline_test\", \"n_codex_test\", \"n_test\"], [\"Stitch\", \"Stitch + Codex\", \"Oracle\"])), axis=\"columns\")\n",
    "df_overlap_long = df_overlap_long.melt(id_vars=\"batch_size\", value_vars=[\"Stitch\", \"Stitch + Codex\", \"Oracle\"], var_name=\"library\", value_name=\"Oracle inventions discovered (count)\")\n",
    "\n",
    "plt.title(\"Discovery of oracle (test set) inventions\")\n",
    "sns.pointplot(data=df_overlap_long, x=\"batch_size\", y=\"Oracle inventions discovered (count)\", hue=\"library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db007501-a15c-4aa2-8a8a-b9b525ca8cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8187b15-10e4-40b6-ab2d-c28a3c27f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn2, venn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6558d-60db-4489-9587-370861d42bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"library_venn_diagrams\", exist_ok=True)\n",
    "os.makedirs(\"library_venn_diagrams/venn2\", exist_ok=True)\n",
    "os.makedirs(\"library_venn_diagrams/venn3\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e248f1a-d918-492f-8572-2aa129bcb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_overlap.iterrows():\n",
    "    plt.figure()\n",
    "    venn2(\n",
    "        subsets=(row[\"n_baseline_only\"], row[\"n_codex_only\"], row[\"n_overlap\"]),\n",
    "        set_labels=(\"Baseline\", \"Codex\"),\n",
    "    )\n",
    "    plt.title(\"Batch size: \" + str(row[\"batch_size\"]))\n",
    "    plt.savefig(f\"library_venn_diagrams/venn2/batch_{row['batch_size']:03d}.png\", dpi=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79c83ca-8969-43ba-82f4-386676fbbed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size, group in df_libraries.groupby(\"batch_size\"):\n",
    "    fns_baseline = set(group[group.condition == \"baseline\"].dreamcoder)\n",
    "    fns_codex = set(group[group.condition == \"codex\"].dreamcoder)\n",
    "    fns_test = set(group[group.condition == \"test\"].dreamcoder)\n",
    "    plt.figure()\n",
    "    venn3(\n",
    "        [fns_baseline, fns_codex, fns_test],\n",
    "        set_labels=(\"Baseline\", \"Codex\", \"Oracle\"),\n",
    "    )\n",
    "    plt.title(\"Batch size: \" + str(batch_size))\n",
    "    plt.savefig(f\"library_venn_diagrams/venn3/batch_{int(batch_size):03d}.png\", dpi=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce11f4-46a0-4a5d-bee1-21f9cc70d7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e0a6d-5a7e-49ad-bab5-e9385eb25412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
