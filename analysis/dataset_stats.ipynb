{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f680e2-6c14-47bc-ab15-acfa2962cb50",
   "metadata": {},
   "source": [
    "# Dataset stats workbook\n",
    "- Created by Gabe (2022-05-07)\n",
    "- For Theo to use to compute dataset statistics\n",
    "- Note: should be run at the top-level of laps/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from run_experiment import init_experiment_state_and_iterator\n",
    "from dreamcoder.program import Program\n",
    "from src.config_builder import build_config\n",
    "from src.experiment_iterator import EXPORT_DIRECTORY\n",
    "from src.task_loaders import GroundTruthOrderedTaskBatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716bfc6c-f74d-4a0f-b632-6426265d889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOMAIN = \"drawings_nuts_bolts\"\n",
    "#DOMAIN = \"drawings_furniture\"\n",
    "#DOMAIN = \"drawings_dials\"\n",
    "#DOMAIN = \"drawings_wheels\"\n",
    "\n",
    "DOMAIN = \"clevr\"\n",
    "#DOMAIN = \"re2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cfe58c-677d-49bc-8f8f-8e3144cac3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = build_config(\n",
    "    experiment_name=\"test_experiment\",\n",
    "    experiment_type=\"stitch\",\n",
    "    domain=DOMAIN,\n",
    "    task_batcher=\"ground_truth_ordered_task_batcher\",\n",
    "    random_seed=111,\n",
    "    global_batch_size=\"all\",\n",
    "    codex_params={},\n",
    "    stitch_params={},\n",
    "    compute_likelihoods=False,\n",
    "    compute_description_lengths=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f292e-f7ed-48c3-adc3-2aa03653d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_state, experiment_iterator = init_experiment_state_and_iterator(\n",
    "    {}, config\n",
    ")\n",
    "experiment_state.initialize_ground_truth_task_frontiers(task_split=\"train\")\n",
    "experiment_state.initialize_ground_truth_task_frontiers(task_split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9bfc11-5d32-4ac6-a169-42b92de4cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frontiers = experiment_state.get_frontiers_for_ids(task_split=\"train\", task_ids=\"all\")\n",
    "print(len(train_frontiers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ee535-e696-4931-8ed9-2afd81b65c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A frontier contains one or more programs that solve a task\n",
    "train_frontiers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55172ba-429d-4dc5-a263-414e6641b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first program in the frontier. You can assume all domains have one program per frontier.\n",
    "p = train_frontiers[0].entries[0].program\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a293639-b791-4ccd-bb7e-7e2f9216487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# description length\n",
    "len(Program.left_order_tokens(p, show_vars=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed51c9-d2a0-48c1-a08b-4354756a94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# character length\n",
    "len(str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0fb726-c5b9-4d18-8ce4-62d9664ac325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(theoxo): Compute and report the following for the paper\n",
    "# - number of programs in each domain, broken down by train/test\n",
    "# - mean and std of description and character lengths for all domains, broken down by train/test\n",
    "# - any other relevant program stats you can think of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e6d38-01e2-4f89-a6ae-842bb2a0af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for t in [\"train\", \"test\"]:\n",
    "    data[t] = {}\n",
    "    frontiers = experiment_state.get_frontiers_for_ids(task_split=t, task_ids=\"all\")\n",
    "    data[t][\"count\"] = len(frontiers)\n",
    "    data[t][\"dls\"] = np.array([len(Program.left_order_tokens(frontier.entries[0].program, show_vars=True)) for frontier in frontiers])\n",
    "    data[t][\"chars\"] = np.array([len(str(frontier.entries[0].program)) for frontier in frontiers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1874c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Domain={DOMAIN}\")\n",
    "print(f\"Number of programs: train={data['train']['count']} test={data['test']['count']}\")\n",
    "print(f\"Mean and std-dev of description length: train={(np.mean(data['train']['dls']), np.std(data['train']['dls']))} test={(np.mean(data['test']['dls']), np.std(data['test']['dls']))}\")\n",
    "print(f\"Mean and std-dev of char length: train={(np.mean(data['train']['chars']), np.std(data['train']['chars']))} test={(np.mean(data['test']['chars']), np.std(data['test']['chars']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13e797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
